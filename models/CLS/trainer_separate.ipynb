{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e30b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Sampler(object):\n",
    "    r\"\"\"Base class for all Samplers.\n",
    "\n",
    "    Every Sampler subclass has to provide an __iter__ method, providing a way\n",
    "    to iterate over indices of dataset elements, and a __len__ method that\n",
    "    returns the length of the returned iterators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class WeightedRandomSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, labels, stratify = None, weights = None):\n",
    "        self.labels = labels\n",
    "        self.label_counts = labels.value_counts().to_dict()\n",
    "        self.num_labels = len(self.label_counts.keys())\n",
    "        \n",
    "        if weights is None:\n",
    "            self.weights = {key: 1 for key, val in self.label_counts.items()}\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        \n",
    "        if stratify == 'increase':\n",
    "            self.samples_per_label = {key: round(max(self.label_counts.values()) * weight) for key, weight in self.weights.items()}\n",
    "        elif stratify == 'decrease':\n",
    "            self.samples_per_label = {key: round(min(self.label_counts.values()) * weight) for key, weight in self.weights.items()}\n",
    "        else:\n",
    "            self.samples_per_label = {key: round(self.label_counts[key] * self.weights[key]) for key in self.weights} \n",
    "        \n",
    "        self.num_samples = sum(self.samples_per_label.values())\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        for lbl, amount in self.samples_per_label.items():\n",
    "            label_data = self.labels[self.labels == lbl]\n",
    "            label_counts = len(label_data)\n",
    "            for i in range(amount // label_counts):\n",
    "                indices += label_data.index[torch.randperm(label_counts)].tolist()\n",
    "            indices += label_data.index[torch.randperm(amount % label_counts)].tolist()\n",
    "        return iter(np.array(indices)[torch.randperm(self.num_samples)].tolist())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef7c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CLS_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, split = [0,1]):\n",
    "        \n",
    "        encs = ['attention_mask', 'input_ids', 'token_type_ids']\n",
    "        dataset = pd.read_csv(f'{data_path}', header = 0, index_col = 0).reset_index()\n",
    "        print(pd.unique(dataset['labels']))\n",
    "        dataset = dataset[round(len(dataset)*split[0]): round(len(dataset)*split[1])]\n",
    "        dataset['labels'] = dataset['labels'].apply(lambda lbl: int(lbl))\n",
    "        tmp = dataset[dataset['labels'] == 1].groupby(['groups']).first().reset_index()\n",
    "        dataset = dataset[dataset['labels'] == 0].append(tmp).reset_index()\n",
    "        \n",
    "        dataset['labels'] += addit\n",
    "        \n",
    "        tqdm.pandas()\n",
    "        \n",
    "        self.encodings = dataset[encs].progress_applymap(literal_eval)\n",
    "        self.encodings['labels'] = dataset['labels']\n",
    "        self.others = dataset.drop(encs + ['labels'], axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encodings.loc[idx].to_dict('list'), self.others.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587bc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class Trainer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 save_path,\n",
    "                 split = [0,1],\n",
    "                 model_path = None,\n",
    "                 num_labels = 2,\n",
    "                 stratify = None,\n",
    "                 sample_weights = None,\n",
    "                 batch_size = 16,\n",
    "                 learning_rate = 5e-5,\n",
    "                 num_epochs = 3,\n",
    "                 warmup_percent = 1,\n",
    "                ):\n",
    "        \n",
    "        self.dataset = CLS_Dataset(data_path, split)\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        if model_path is None:\n",
    "            self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = num_labels)\n",
    "        else:\n",
    "            self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.wrs = WeightedRandomSampler(self.dataset.encodings['labels'], stratify = stratify, weights = sample_weights)\n",
    "        sampler = torch.utils.data.sampler.BatchSampler(self.wrs, batch_size=batch_size,drop_last=False)\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast = True)\n",
    "        \n",
    "        dataCollator = DataCollatorWithPadding(tokenizer = self.tokenizer)\n",
    "        self.train_loader = DataLoader(dataset = self.dataset, \n",
    "                                       batch_size = None, \n",
    "                                       collate_fn = lambda x: dataCollator(x[0]), \n",
    "                                       sampler = sampler)\n",
    "        \n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_warmup_steps = round(num_epochs * len(self.train_loader) * warmup_percent / (batch_size * 100)) * batch_size\n",
    "        self.num_training_steps = num_epochs * len(self.train_loader)\n",
    "        self.lr_scheduler = get_scheduler(\"linear\", \n",
    "                                     optimizer = self.optimizer, \n",
    "                                     num_warmup_steps = self.num_warmup_steps, \n",
    "                                     num_training_steps = self.num_training_steps)\n",
    "    \n",
    "    def train(self, save = True, evaluator = None):\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.model.to(device)\n",
    "        \n",
    "        progress_bar_train = tqdm(range(self.num_training_steps))\n",
    "        \n",
    "        losses = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "                #if i > 10: break\n",
    "                enc = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = self.model(**enc)\n",
    "                loss = outputs.loss\n",
    "                losses += [loss.detach().cpu()]\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "                self.lr_scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                progress_bar_train.update(1)\n",
    "                \n",
    "                if i % round(len(self.train_loader)/3) == 1:\n",
    "                    print(f'Average loss: {sum(losses)/len(losses)}')\n",
    "                    losses = []\n",
    "            if evaluator is not None:\n",
    "                self.model.eval()\n",
    "                evaluator.evaluate(self.model)\n",
    "        if save:\n",
    "            self.model.save_pretrained(self.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8f61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "class Evaluator():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 split = [0,1],\n",
    "                 stratify = None,\n",
    "                 sample_weights = None,\n",
    "                 batch_size = 16\n",
    "                ):\n",
    "        \n",
    "        self.dataset = CLS_Dataset(data_path, split)\n",
    "        wrs = WeightedRandomSampler(self.dataset.encodings['labels'], stratify = stratify, weights = sample_weights)\n",
    "        sampler = torch.utils.data.sampler.BatchSampler(wrs, batch_size=batch_size,drop_last=False)\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast = True)\n",
    "        dataCollator = DataCollatorWithPadding(tokenizer = self.tokenizer)\n",
    "        self.eval_loader = DataLoader(dataset = self.dataset, \n",
    "                                       batch_size = None, \n",
    "                                       collate_fn = lambda x: (dataCollator(x[0]), x[1]), \n",
    "                                       sampler = sampler)\n",
    "        \n",
    "    \n",
    "    def evaluate(self, model):\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "\n",
    "        groups = []\n",
    "        lgits = []\n",
    "        lgits_bin = []\n",
    "        preds = []\n",
    "        refs = []\n",
    "        opts = []\n",
    "\n",
    "        model.eval()\n",
    "        self.progress_bar_eval = tqdm(range(len(self.eval_loader)))\n",
    "        self.progress_bar_eval.reset()\n",
    "        for i, (enc, others) in enumerate(self.eval_loader):\n",
    "            #if i > 10: break\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**enc)\n",
    "            logits = outputs.logits\n",
    "            vals, predictions = torch.max(logits, dim=-1)\n",
    "            groups += others['groups'].tolist()\n",
    "            lgits_bin += logits[:,1+addit].detach().cpu()\n",
    "            lgits += vals.detach().cpu()\n",
    "            preds += predictions.detach().cpu() - addit\n",
    "            refs += enc['labels'].detach().cpu() - addit\n",
    "\n",
    "            self.progress_bar_eval.update(1)\n",
    "        \n",
    "        df = pd.DataFrame({'groups': groups, 'logits': lgits, 'logits_bin': lgits_bin, 'preds': preds, 'refs': refs})\n",
    "        print(\"-\"*20 + \"----------\" + \"-\"*20)\n",
    "        print(df.head())\n",
    "        prec, rec, f1, dist = metrics.precision_recall_fscore_support(refs, preds, average=None)\n",
    "        print(\"-\"*20 + \"EVALUATION\" + \"-\"*20)\n",
    "        print('Precision: \\t\\t{}'.format(prec))\n",
    "        print('Recall: \\t\\t{}'.format(rec))\n",
    "        print('F1: \\t\\t\\t{}'.format(f1))\n",
    "        print('Distribution: \\t\\t{}'.format(dist))\n",
    "        \n",
    "        print(\"Original task: \\t\\t{}\".format(df[(df.groupby('groups'))['logits_bin'].transform(max) == df['logits_bin']]['refs'].mean()))\n",
    "        \n",
    "        tmp = df[(df.groupby('groups'))['logits'].transform(max) == df['logits']]\n",
    "        print(\"Original task v2: \\t{}\".format(len(tmp[tmp['preds'] == tmp['refs']].groupby('groups').first())/len(df.groupby('groups').first())))\n",
    "        \n",
    "        print(\"-\"*20 + \"----------\" + \"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe81be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1 = 'incorrect'\n",
    "sen2 = 'explanation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ae3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8a6bf5283c4c6fb15e74219a80556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08565f2aeeec442f8896fef211050c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2445 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.8940809965133667\n",
      "Average loss: 0.7197940945625305\n",
      "Average loss: 0.6927849054336548\n",
      "Average loss: 0.6727956533432007\n",
      "Average loss: 0.5723435282707214\n",
      "Average loss: 0.5591082572937012\n",
      "Average loss: 0.5627303123474121\n",
      "Average loss: 0.28720608353614807\n",
      "Average loss: 0.28685641288757324\n"
     ]
    }
   ],
   "source": [
    "addit = 0\n",
    "trainer = Trainer(data_path = '../../data/generated/multitask/separate/ecqa_train_bert.csv', \n",
    "                  save_path = 'ECQA/Gen3_notft',\n",
    "                  num_labels = 3,\n",
    "                  #model_path = 'eSNLI/Gen3', \n",
    "                  #split = [0.25,0.5],\n",
    "                  num_epochs = 3, \n",
    "                  batch_size = 16,\n",
    "                  stratify = 'decrease')\n",
    "trainer.train(save = True)#, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5abc0a",
   "metadata": {},
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a6eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('ECQA/Gen3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75c73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "addit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614f6c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209b6efff68944d0b1dd53b283e9469e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = Evaluator(data_path = '../../data/tokenized/bert/ecqa/test.csv', \n",
    "#evaluator = Evaluator(data_path = '../../data/generated/multitask/separate/ecqa_test_bert.csv', \n",
    "                          #split = [0.4,0.6], \n",
    "                          batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9cd625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c44e5914bc944dea864a089e0dc7bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "                             groups          logits       logits_bin  \\\n",
      "0  8d87db96a87432ee5f01d24326b121b5  tensor(3.4676)  tensor(-3.7930)   \n",
      "1  ddea491827544bc6d1a9e3aa715817cf  tensor(0.2067)   tensor(0.2067)   \n",
      "2  37743518d3b95c18cc0e820c2eb6175f  tensor(1.5626)  tensor(-1.4801)   \n",
      "3  19629ab397ea8f1bdc46629668c62af2  tensor(3.2118)  tensor(-3.3375)   \n",
      "4  2156156d215e0fe1ded434bd40a7f3d8  tensor(1.2851)   tensor(1.2851)   \n",
      "\n",
      "       preds       refs  \n",
      "0  tensor(0)  tensor(0)  \n",
      "1  tensor(1)  tensor(0)  \n",
      "2  tensor(0)  tensor(0)  \n",
      "3  tensor(0)  tensor(1)  \n",
      "4  tensor(1)  tensor(1)  \n",
      "--------------------EVALUATION--------------------\n",
      "Precision: \t\t[0.88026706 0.40933642]\n",
      "Recall: \t\t[0.7948821  0.56798715]\n",
      "F1: \t\t\t[0.83539848 0.47578475]\n",
      "Distribution: \t\t[7464 1868]\n",
      "Original task: \t\t0.5048179871520343\n",
      "Original task v2: \t0.8832976445396146\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluator.evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f05a7a",
   "metadata": {},
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0ab9f",
   "metadata": {},
   "source": [
    "addit = 2\n",
    "for sepsh in ['separate']:\n",
    "    for stmt in ['singletask']:\n",
    "        try:\n",
    "            evaluator = Evaluator(data_path = '../../data/generated/{}/{}/esnli_test_bert.csv'.format(stmt, sepsh), \n",
    "                          #split = [0.4,0.6], \n",
    "                          batch_size = 32)\n",
    "            evaluator.evaluate(model)\n",
    "        except:\n",
    "            print('FAILED: ../../data/generated/{}/{}/esnli_test_bert.csv'.format(stmt, sepsh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef97a4",
   "metadata": {},
   "source": [
    "pd.unique(evaluator.dataset.encodings['labels'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
